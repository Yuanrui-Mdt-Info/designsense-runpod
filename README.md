# Stable Diffusion WebUI RunPod Serverless Worker

è¿™æ˜¯ä¸€ä¸ªç”¨äºåœ¨ [RunPod](https://www.runpod.io/) Serverless å¹³å°ä¸Šéƒ¨ç½² [Stable Diffusion WebUI (AUTOMATIC1111)](https://github.com/AUTOMATIC1111/stable-diffusion-webui) çš„ Docker é•œåƒé¡¹ç›®ã€‚

å®ƒå°† WebUI å°è£…ä¸ºä¸€ä¸ª Serverless Workerï¼Œé€šè¿‡ RunPod API å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚ï¼Œéå¸¸é€‚åˆæ„å»ºæŒ‰éœ€ä»˜è´¹çš„ AI ç»˜å›¾åº”ç”¨ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ åŸºäº NVIDIA CUDA 12.1 & PyTorch 2.1.0 æ„å»º
- ğŸ¨ é›†æˆ AUTOMATIC1111 Stable Diffusion WebUI (v1.10.1)
- ğŸ æ¨èä½¿ç”¨ Python 3.10.x ä»¥è·å¾—æœ€ä½³å…¼å®¹æ€§
- ğŸ”Œ æ”¯æŒå¤šç§ API æ“ä½œï¼š
  - `txt2img` (æ–‡ç”Ÿå›¾)
  - `img2img` (å›¾ç”Ÿå›¾)
  - `ControlNet` (å§¿æ€/è¾¹ç¼˜æ§åˆ¶ç­‰)
  - `LoRA`
  - æ¨¡å‹ç®¡ç†ä¸é€‰é¡¹é…ç½®

## ğŸ§ª åœ¨ RunPod Pod ä¸Šå¿«é€Ÿè°ƒè¯•ï¼ˆæ¨èï¼‰

å¦‚æœä½ æƒ³å¿«é€Ÿè°ƒè¯•è€Œä¸æ„å»º Docker é•œåƒï¼Œå¯ä»¥ç›´æ¥åœ¨ RunPod Pod ä¸Šè¿è¡Œï¼š

### 1. å¯åŠ¨ Pod
1. åœ¨ RunPod Console åˆ›å»ºä¸€ä¸ª GPU Pod
2. é€‰æ‹©é•œåƒï¼š`pytorch/pytorch:2.1.2-cuda12.1-cudnn8-runtime` (Python 3.10)
3. é€‰æ‹© GPUï¼šRTX 3090 æˆ– RTX 4090ï¼ˆä¾¿å®œä¸”å¤Ÿç”¨ï¼‰
4. å¯åŠ¨ Podï¼Œé€šè¿‡ SSH æˆ– Jupyter Lab è¿æ¥

### 2. è¿è¡Œç¯å¢ƒé…ç½®è„šæœ¬
å°†é¡¹ç›®ä»£ç ä¸Šä¼ åˆ° Podï¼Œç„¶åè¿è¡Œï¼š

```bash
cd /workspace/ä½ çš„é¡¹ç›®ç›®å½•
chmod +x setup_dev.sh
./setup_dev.sh
```

`setup_dev.sh` ä¼šè‡ªåŠ¨å®Œæˆï¼š
- å®‰è£…ç³»ç»Ÿä¾èµ–å’Œ Python åŒ…
- å…‹éš† Stable Diffusion WebUI v1.10.1
- ä¸‹è½½ SD v1.5 æ¨¡å‹ï¼ˆçº¦ 4GBï¼‰
- é…ç½®è¿è¡Œç¯å¢ƒ

### 3. å¯åŠ¨æœåŠ¡
```bash
cd /workspace/webui
./start.sh
```

çœ‹åˆ° `Model loaded in ...s` å’Œ `WebUI API Service is ready` å³è¡¨ç¤ºæˆåŠŸï¼

### 4. æµ‹è¯• API
åœ¨ Pod ç»ˆç«¯åˆ›å»ºæµ‹è¯•è„šæœ¬ï¼š

```bash
cat > test_txt2img.py << 'EOF'
import requests

url = "http://127.0.0.1:3000/sdapi/v1/txt2img"
payload = {
    "prompt": "a cute cat, high quality, 8k",
    "steps": 20,
    "width": 512,
    "height": 512
}

response = requests.post(url, json=payload, timeout=120)
if response.status_code == 200:
    print("Success! Image generated.")
else:
    print(f"Error: {response.status_code}")
EOF

python test_txt2img.py
```

## ğŸ› ï¸ æ„å»º Docker é•œåƒï¼ˆç”Ÿäº§éƒ¨ç½²ï¼‰

å½“ä½ åœ¨ Pod ä¸Šè°ƒè¯•å®Œæˆåï¼Œå¯ä»¥æ„å»ºé•œåƒç”¨äº Serverless éƒ¨ç½²ã€‚

### 1. æ„å»ºå‘½ä»¤

åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹å‘½ä»¤æ„å»ºé•œåƒï¼š

```bash
# è¯·å°† your-username æ›¿æ¢ä¸ºä½ çš„ Docker Hub ç”¨æˆ·å
docker build -t your-username/sd-runpod-serverless:v1 .
```

**æ³¨æ„**ï¼šé•œåƒä¸­**ä¸åŒ…å«æ¨¡å‹æ–‡ä»¶**ï¼Œæ¨¡å‹éœ€è¦é€šè¿‡ Network Volume æŒ‚è½½ã€‚

### 2. æ¨é€é•œåƒ

å°†é•œåƒæ¨é€åˆ° Docker Hubï¼ˆæˆ–å…¶ä»–å®¹å™¨é•œåƒä»“åº“ï¼‰ï¼Œä»¥ä¾¿ RunPod æ‹‰å–ï¼š

```bash
docker push your-username/sd-runpod-serverless:v1
```

## ğŸš€ éƒ¨ç½²åˆ° RunPod Serverless

### 0. å‡†å¤‡æ¨¡å‹æ–‡ä»¶ï¼ˆNetwork Volumeï¼‰

1. åœ¨ RunPod Console å¯¼èˆªåˆ° **Storage** -> **Network Volumes**
2. åˆ›å»ºä¸€ä¸ªæ–°çš„ Network Volumeï¼ˆå»ºè®® 20GB+ï¼‰
3. é€šè¿‡ Pod æŒ‚è½½è¿™ä¸ª Volumeï¼Œä¸Šä¼ æ¨¡å‹æ–‡ä»¶åˆ° `models/Stable-diffusion/` ç›®å½•

**æ¨èæ¨¡å‹**ï¼š
- **SD v1.5**ï¼ˆå¿«é€Ÿã€å…¼å®¹æ€§å¥½ï¼‰ï¼š
  ```bash
  wget -O model.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors
  ```
- **SDXL Turbo**ï¼ˆé«˜è´¨é‡ã€1024Ã—1024ï¼‰ï¼š
  ```bash
  wget -O sd_xl_turbo.safetensors https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0_fp16.safetensors
  ```

### 1. åˆ›å»º Template (æ¨¡æ¿)

1. ç™»å½• [RunPod Console](https://www.runpod.io/console/serverless)
2. å¯¼èˆªåˆ° **Templates** -> **New Template**
3. å¡«å†™é…ç½®ï¼š
   - **Template Name**: ä¾‹å¦‚ `SD WebUI Serverless v1.10.1`
   - **Container Image**: `your-username/sd-runpod-serverless:v1` (ä½ æ¨é€çš„é•œåƒåœ°å€)
   - **Container Disk**: å»ºè®® `10 GB` (é•œåƒæœ¬èº«ä¸å¤§)
   - **Docker Command**: ç•™ç©º (ä½¿ç”¨ Dockerfile é»˜è®¤ CMD)
   - **Volume Mount Path**: `/workspace/webui/models/Stable-diffusion`
   - **Volume Path**: é€‰æ‹©ä½ ä¸Šä¼ äº†æ¨¡å‹çš„ Network Volume
4. ç‚¹å‡» **Save Template**

### 2. åˆ›å»º Serverless Endpoint

1. å¯¼èˆªåˆ° **Serverless** -> **New Endpoint**
2. é€‰æ‹©åˆšæ‰åˆ›å»ºçš„ Template
3. é…ç½® GPUï¼š
   - é€‰æ‹©é€‚åˆçš„ GPU ç±»å‹ (å¦‚ RTX 3090, A4000 ç­‰)
   - è®¾ç½® Min/Max Workersï¼ˆå»ºè®® Min: 0, Max: 3ï¼‰
4. ç‚¹å‡» **Create** éƒ¨ç½²

## ğŸ“¡ API è°ƒç”¨è¯´æ˜

éƒ¨ç½²å®Œæˆåï¼Œä½ ä¼šè·å¾—ä¸€ä¸ª Endpoint IDã€‚ä½¿ç”¨ RunPod SDK æˆ– HTTP è¯·æ±‚è°ƒç”¨ã€‚

### è¯·æ±‚å‚æ•°ç»“æ„

Worker æ¥æ”¶çš„ `input` å¯¹è±¡åŒ…å« `api_name` å’Œå¯¹åº”çš„å‚æ•°ã€‚

#### ç¤ºä¾‹ 1: æ–‡ç”Ÿå›¾ (txt2img)

```json
{
  "input": {
    "api_name": "txt2img",
    "prompt": "masterpiece, best quality, 1girl, looking at viewer, solo, upper body, highres, 8k",
    "negative_prompt": "easynegative, low quality, bad anatomy",
    "steps": 25,
    "width": 512,
    "height": 768,
    "sampler_name": "Euler a",
    "cfg_scale": 7
  }
}
```

#### ç¤ºä¾‹ 2: è·å–æ¨¡å‹åˆ—è¡¨ (getModels)

```json
{
  "input": {
    "api_name": "getModels"
  }
}
```

### æ”¯æŒçš„ API åˆ—è¡¨

åœ¨ `rp_handler.py` ä¸­å®šä¹‰äº†æ‰€æœ‰æ”¯æŒçš„æ¥å£ï¼š

- `txt2img`: POST `/sdapi/v1/txt2img`
- `img2img`: POST `/sdapi/v1/img2img`
- `png-info`: POST `/sdapi/v1/png-info`
- `getModels`: GET `/sdapi/v1/sd-models`
- `getOptions`: GET `/sdapi/v1/options`
- `setOptions`: POST `/sdapi/v1/options`
- `getControlNetModels`: GET `/controlnet/model_list`
- `getControlNetModules`: GET `/controlnet/module_list`
- `getControlNetDetect`: POST `/controlnet/detect`
- `getLora`: GET `/sdapi/v1/loras`

## ğŸ› å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆæ¨è Python 3.10 è€Œä¸æ˜¯ 3.11/3.12ï¼Ÿ
A: Stable Diffusion ç”Ÿæ€ï¼ˆPyTorch, xformers ç­‰ï¼‰å¯¹ Python 3.10 çš„æ”¯æŒæœ€å¥½ï¼Œé¢„ç¼–è¯‘åŒ…æœ€å…¨ï¼Œå¯ä»¥é¿å…ç¼–è¯‘å¤±è´¥çš„é—®é¢˜ã€‚

### Q: ä¸ºä»€ä¹ˆä¼šæç¤º `no module 'xformers'`ï¼Ÿ
A: xformers æ˜¯å¯é€‰çš„åŠ é€Ÿåº“ï¼Œæ²¡æœ‰å®ƒä¹Ÿèƒ½è¿è¡Œï¼Œåªæ˜¯é€Ÿåº¦ä¼šæ…¢ 20-30%ã€‚å¦‚æœéœ€è¦å®‰è£…ï¼š`pip install xformers`ã€‚

### Q: SD v1.5 å’Œ SDXL Turbo è¯¥é€‰å“ªä¸ªï¼Ÿ
A: 
- **SD v1.5**: é€Ÿåº¦å¿«ï¼ˆ512Ã—512ï¼‰ï¼Œæ˜¾å­˜å ç”¨å°ï¼ˆ4-6GBï¼‰ï¼Œæ’ä»¶ç”Ÿæ€ä¸°å¯Œï¼Œ**æ¨èè°ƒè¯•å’Œå¿«é€Ÿå‡ºå›¾**
- **SDXL Turbo**: è´¨é‡é«˜ï¼ˆ1024Ã—1024ï¼‰ï¼Œæ˜¾å­˜å ç”¨å¤§ï¼ˆ8-12GBï¼‰ï¼Œ**æ¨èç”Ÿäº§ç¯å¢ƒè¿½æ±‚è´¨é‡**

### Q: å¦‚ä½•åœ¨ Pod ä¸ŠæŒä¹…åŒ–æ•°æ®ï¼Ÿ
A: RunPod Pod çš„ `/workspace` ç›®å½•é»˜è®¤æ˜¯æŒä¹…åŒ–çš„ï¼Œå³ä½¿åœæ­¢ Pod å†å¯åŠ¨ï¼Œæ•°æ®ä¾ç„¶ä¿ç•™ã€‚

## ğŸ’» æœ¬åœ°å¼€å‘/è°ƒè¯•

å¦‚æœä½ æœ‰ NVIDIA GPUï¼Œå¯ä»¥åœ¨æœ¬åœ°è¿è¡Œæµ‹è¯•ï¼š

```bash
docker run --gpus all -p 3000:3000 \
  -v /path/to/your/models:/workspace/webui/models/Stable-diffusion \
  your-username/sd-runpod-serverless:v1
```

å®¹å™¨å¯åŠ¨åï¼Œè®¿é—® `http://localhost:3000/docs` æŸ¥çœ‹ API æ–‡æ¡£ã€‚

## ğŸ“ æŠ€æœ¯æ ˆ

- **Base Image**: `nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04`
- **Python**: 3.10.x (æ¨è)
- **PyTorch**: 2.1.0 (CUDA 11.8)
- **WebUI Version**: AUTOMATIC1111 v1.10.1
- **RunPod SDK**: 1.7.13

## ğŸ“„ License

MIT License
